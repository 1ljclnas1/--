# 概述

随着业务增长，服务器计算力不足，于是研究者开始在堕胎服务器上部署相同的应用，以提升整体服务的并发处理能力，这种部署方式称为**集群**

集群是指拥有相同功能的一组成员，它们联合起来整体向外提供服务。

分布式是指将同一个应用的不同功能模块分别部署，它们之间通过约定的通信协议进行交互。

后端部署中**分布式+集群**的部署方式很常见。

集群除了提升并发处理能力以外，还常用于满足容错性。

要想使用集群来满足容错性一般有两种方式：

1. 主备同步

2. 对等服务。如何保持多个数据成员数据对齐？状态机！

## 状态机

状态机从一个初始状态开始，每一次输入都将传入转换函数，使得状态机进入一个新的状态。在下一个输入到来之前，状态不变。

可以将集群中的成员看成一个个状态机。，他们都从相同的初始状态开始，并按照相同的输入顺序执行转换函数，最终成员的状态是一致的。

状态机解决了集群满足容错性的必要条件（数据对齐）。

## 共识简介

基于状态机的分布式系统最关键的是决定输入的顺序。因为相同的输入顺序才能使所有非错误的成员达到相同的状态。才能保证数据一致，并且能随时构建无限多个一摸一样的完整状态机。

为了**使一组成员拥有相同顺序的一组输入**，我们需要在状态机上在设计一个**保证协议**，即**共识算法**

### 共识的概念

一组成员组成一个分布式共识系统，他服务于多个客户端，每个客户端都可以提出多个提案，从而组成一个提案集合。共识算法需要保证：**从客户端看来，系统中所有成员都选择了同一个提案。**换句话说，让多个成员在外界看起来是一个成员、

共识问题是指：在分布式系统中，要求一组成员（可能发生故障）根据它们（可能冲突）的输入，就共同输出达成共识。在分布式环境中，每个成员都可能因为请求顺序而接受不同的值，并且每个成员都可能发生故障，甚至可能存在恶意伪造请求成员的问题。

由于应用场景的问题，共识算法也存在明显的区别。在区块链应用中，系统建立在去中心化的环境下，每个成员都提供平等的服务，系统没有一个权威的中心来处理运行中出现的异常问题。因此，一些不法分子通过部署大量的恶意成员来影响最终达成决策的值，基于此，区块链系统通常会附加一些激励模型和治理模型来激励正常工作的成员，使越来越多愿意正常工作的成员加入共识决策中，以增加恶意成员的恶意成本。

传统的后端分布式系统通常部署在局域网环境中，这极大的减少了出现恶意成员的概率。同时，也可以设立一个具有特殊角色的成员来处理运行中产生的异常情况，如ZooKeeper中的ZAB算法和Raft算法等。

但这并不意味着完全对等的部署架构在后端中不存在，引入权威的中央成员会极大的降低系统的可用性和横向扩展性。可用性的降低是因为中央成员也可能出现故障，横向扩展性降低是因为中央权威成员的特殊性意味着他不可能大规模部署。因此仍然有一些钩端的分布式系统采用弱中心化算法如Multi Paxos，也有一些中间件在规划采用EPaxos如Cassandra。

### 共识与集群

共识算法运行在集群之上。集群在没有共识算法的时候，能提升的只有并发处理能力，而共识是为了所有成员都认同某一个值。

共识与集群的最大区别是成员之间数据的处理方式不同。集群通常需要引入一个额外的存储服务来保证数据一致性。而共识就是为了解决数据一致性存在的。因此它不需要依赖额外的数据存储服务。比如ZooKeeper，自身的ZAB协议就能保证数据一致性，但是对于业务逻辑系统就需要一个额外的公共数据库。

### 共识与副本

在设计一个数据库时，为了满足容错性，需要多个成员同时提供数据库服务。在执行写操作的时候，如何使成员的数据保持一致性有以下两种方案：

1. 使用副本模式。约定Leader，让Leader执行写操作，然后将请求转发给备用成员。这种方案有两个问题
   
   1. 数据延迟 Slave的数据不是最新的，要读取最新的数据只能将压力放在Leader上，因此Leader将成为读请求的瓶颈。
   
   2. 数据不一致  Leader处理成功，但Slave未收到对应的数据或Slave处理失败。如果Leader故障将丢失一部分数据。

2. 所有成员都执行写操作。在所有成员都成功后，这次操作才算成功。问题是写操作受限于缓慢成员的处理时效，且无法保证所有成员都成功执行写操作，这会降低系统的可用性。而且还要处理失败回滚的操作，而回滚也有失败的就可能性。

因此，共识问题只有通过共识算法解决。

### 共识与一致性

在外界观察者看来，共识系统中的所有成员是一致的，但实际上并不是，因此一致包含共识。CAP定理描述一致性、可用性、分区容错性三者只能取其二。共识算法可以理解为放弃一部分成员的一致性而增加了可用性。

## 拜占庭故障

拜占庭故障（Byzantine Fault）是分布式系统中一种特殊的故障类型，它涉及到系统中的节点之间出现任意类型的错误或恶意行为。这些错误或恶意行为可能会导致节点之间的通信产生不一致的结果或误导其他节点。

拜占庭故障模型最早由拜占庭将军问题引入，用于描述在一个将军团队中，部分将军是不可信的情况下如何达成一致的决策。在分布式系统中，节点可能受到网络延迟、硬件故障、恶意攻击等因素的影响，进而产生拜占庭故障。

拜占庭故障的特点包括以下几个方面：

1. 不可靠性：拜占庭节点可能发送错误、无效或伪造的信息，也可能选择不发送信息。
2. 同步问题：由于网络延迟或节点故障，节点之间的消息传递可能存在延迟或丢失的情况。
3. 无法区分故障和恶意行为：对于接收到的消息，无法确定是否是因为故障导致的错误还是恶意节点的攻击行为。

解决拜占庭故障的问题是分布式系统设计中的一个重要挑战。一些经典的拜占庭容错算法（Byzantine Fault Tolerance, BFT）被提出，例如拜占庭共识算法、拜占庭容错一致性算法等。这些算法通过使用消息认证、多数投票、冗余计算、公钥密码学等技术手段来检测和纠正拜占庭节点的错误行为，从而保证系统在面对拜占庭故障时依然能够达成共识并正确运行。

拜占庭故障具有一定的复杂性和挑战性，因此在设计和实现分布式系统时需要仔细考虑拜占庭故障的可能性，并选择合适的拜占庭容错策略以提高系统的可靠性和安全性。

### 拜占庭解决方案

Lamport在他的论文《The Byzantine Generals Problem》中提到了一种拜占庭解决方案，被称为Lamport's Algorithm（Lamport算法）。该算法由Leslie Lamport于1982年提出，是早期用于解决拜占庭将军问题的算法之一。

Lamport算法的主要思想是通过两个阶段的投票和反馈来达成一致。以下是Lamport算法的基本步骤：

1. 提议阶段（Proposal Phase）：
   
   - 每个将军向其他将军发送自己的提议（可以是某个具体的值或决策）。
   - 收到提议的将军将它们保存下来，并将提议转发给其他将军。

2. 投票阶段（Voting Phase）：
   
   - 每个将军向其他将军发送自己的投票（同意或不同意）。
   - 收到投票的将军将它们保存下来，并将投票转发给其他将军。

3. 决策阶段（Decision Phase）：
   
   - 每个将军根据收到的投票，决定自己的最终决策。
   - 最终决策可以是收到投票中的多数决策，或者是某种预定义的默认决策。

Lamport算法的关键点在于，它要求至少3f+1个将军中有至少f+1个将军是忠诚可靠的，才能保证最终的一致性。在存在f个拜占庭将军的情况下，Lamport算法能够达成一致的决策，前提是忠诚将军之间可以直接通信。

需要注意的是，Lamport算法并不是完全解决了拜占庭将军问题，因为它依赖于一定数量的忠诚将军。后续的研究和算法扩展进一步改进了对拜占庭将军问题的解决方案，如PBFT（Practical Byzantine Fault Tolerance）等。但Lamport算法作为早期的拜占庭解决方案之一，对该领域的研究起到了重要的推动作用。

## 小结

分布式 --> 状态机 --> 共识算法是层层递进的

分布式：突破了集中式架构的瓶颈

状态机：满足了容错性

共识算法：保证了状态机的输入一致性。

共识强调的是在外界看来系统中所有成员的数据是一致的，而CAP中的一致性是指，集群中所有成员的数据保持真正的一致。

# 从ACID和BASE到CAP

戏称CAP定理为分布式系统的“PH试纸”，因为CAP定理提到的两种系统架构AP和CP是对ACID和BASE的眼神。

## ACID追求一致性

ACID为了保证数据的完整性，总结出事务的4个特性：原子性，一致性，隔离性，持久性。

## BASE理论---追求可用性

最早可追溯至1997年Eric Brewer分享的名为Cluster-Based scalable Network Services的演讲。随后2008年EBay工程师Dan Pritchett在论文Base: An Acid Alternative中给出了实现Base架构模型的解决方案。

Eric Brewer在演讲中提出了一种弱于ACID特性的架构模型，为了系统的健壮性而依赖于软状态。

### BASE理论的三个方面

基本可用：当分布式系统出现故障时，允许损失部分可用性，但不等于系统不可用。响应时间的损失（不拒绝服务）和功能上的降级（一部分请求返回降级的数据，而不会真正请求后端核心系统，以保证后端系统的稳定性）

软状态：允许系统中的数据存在中间状态，并认为该状态不会影响系统的整体可用性，即允许节点之间的数据同步存在延迟。

最终的一致性：系统的所有副本在经过一个时间期限后最终达到一致的状态。

对于不同的业务场景和架构设计，时间期限长短有较大的差异，只要整体在用户能够接受的范围内即可。每个应用可以给根据自身的业务特点、采用适当的方式使系统最终达到一致性。

### BASE理论的应用

应用于多个微服务之间的调用，大多数应用都会被拆分为多个负责单一功能的服务，一个用户请求往往需要多个服务配合才能完成。而对于一个强一致性系统，可用性都是所依赖服务的可用性的乘积。将一个大型系统拆分为多个微服务，势必会降低系统的可用性，而解决这一困局的就是BASE理论。允许存在软状态的基础上，只需要保证整个事物的基本可用行和最终的一致性。实现这个方案通常采用异步补偿机制。明确哪些是非关键操作，允许非关键操作失败，如果非关键操作失败，则允许业务流程继续执行，然后再异步补偿非关键操作，以此降低非关键操作失败对于整个事务可用性的影响。

在实现异步补偿机制时需要注意以下几点：

- 每个补偿操作都应设置重试机制，且需要实现幂等。

- 整个事务应由工作流驱动，记录每个分支数据的处理结果。

- 对于事务状态，通常需要提供特殊的接口进行·查询

- 对于所有分支事务，需要提供回滚事务的接口。

## CAP 分布式系统的PH试纸

CAP是前人对架构设计经验的总结。

### CAP定理

#### cap猜想

- 一致性：所有节点数据时时保持一致

- 可用性：任何情况都能够处理客户端的每个请求

- 分区容错性：发生分区时，系统应持续提供服务

CAP猜想核心是：任何分布式系统，其一致性、可用性、分区容错性最多只能满足其中两个。

任何分布式系统都可以归结为三类CA CP AP

CP（锁定事务资源）: 所有节点数据时时保持一致，这意味着的当处理写请求时，需锁定各分支事务的资源。当发生分区时，个节点之间不能联通，请求完成所需时间将以来分区的恢复时间。在此期间为了确保返回客户端数据的准确性并且不破坏一致性，可能会因为无法响应最新数据而拒绝响应，即放弃A。

AP（尽最大能力提供服务）：要求每个节点拥有集群的所有能力和数据，能自己处理客户端的每个请求，这样才能实现尽最大能力容错的请求。当发生分区时，可以通过缓存或者本地数据来处理客户端的请求，以达到可用性，但是各个节点数据将会出现不一致的情况，即放弃C。

CA（本地一致性）：在不考虑P的情况下，意味着集群正常运行，一直性和可用性是可以同时满足的。但网络本身是不可靠的，分区永远可能会发生，因此选择CA的系统通常会在发生分区的时候让各子分区满足CA。

#### CAP定理描述

一致性：被形容为原子性和串行化，每个读\写操作都像是一个原子操作，并且像全局排好序一样，后面的读操作一定能读到前面的写操作。这意味着在分布式系统中执行一个写操作就像是在单节点上执行一样。

可用性：系统中未发生故障的节点，收到的每个请求都必须响应，即每个请求最终都必须终止，但不要求终止前所需时间长短。

分区容错性：允许集群中丢失任意数量的消息。

### 为什么C，A，P不可兼得

网络分区必然存在因此P一定存在

C，A，P三者不可兼得变为如何在C和A之间抉择。

在分布式环境中，为了确保系统的可用性，通常将数据复制到多个备份节点上，而复制的过程需要网络交互。当发生网络分区的时候，将面临两个抉择：

1. 如果坚持保持节点之间的数据一致性，则需要等待网络恢复之后将数据复制完成才能对外提供服务。

2. 如果坚持可用性，则发生网络分区的时候依然要对外提供服务。但由于网络分区的原因，同步不了最新的数据，因此返回的数据可能不是最新的数据。

由此可见在发生分区的时候只能在C，A之间选择一个。

### CAP应用

指导作用是不要浪费精力去设计一个满足一致性、可用性和分区容错性·三者的完美系统，而需要根据业务场景进行取舍。生产环境中更多的是对一致性和可用性之间的调节。

# 2PC,3PC----分布式事务的解决方案

## 二阶段提交协议

由于各个分支事务只能知道自己执行的结果是成功还是失败，并不清楚其他分支事务的执行结果，因此需要设计一个协调者的身份，各个分支事务向协调者上报执行状态，再由协调者根据各个分之十五的执行结果决定全局事务的提交或者回滚。

- 协调者：可以由事务发起者充当，也可以有第三方组件充当，如Seata的TC角色。协调者维护全局事务和分支事务的状态，驱动全局事务和分支事务提交或回滚。

- 参与者：通常由各个资源管理者充当，负责执行各个分支事务提交或回滚，并向协调者汇报执行状态。

准备阶段和提交回滚阶段。第一阶段用于各个分支事务的资源锁定，第二阶段用于全局事务的提交和回滚。、

准备阶段：

1. 开启全局事务：协调者收到客户端请求后，将各个分支事务需要处理的内容通过Prepare请求发送给各个协调者，并等待回复

2. 处理分支事务：收到协调者的Prepare请求后锁定事务资源，然后尝试执行各自的分支事务，记录Undo和Redo信息，但不提交。

3. 汇报分支事务状态：参与者根据（2）步执行的结果，相协调这汇报各自的分支事务状态。Yes/No

提交回滚阶段：

1. 驱动全局事务提交/回滚：如果协调者在约定的时间期限内收到所有参与者的Yes则触发全局事务提交，否则回滚。

2. 提交/回滚分支事务：根据Undo/Redo信息对各自分支事务进行提交/回滚，并释放第一阶段的锁定事务资源。

3. 汇报分支事务状态：参与者在处理提交/回滚分支事务后，相协调这反馈自己负责的分支事务状态。

4. 关闭全局事务。

主要掌握以下两点：

- 应用场景：适用于强一致性场景。例如，分布式事务中，多个分支事务组成的整体操作需要具备原子性。

- 核心思想：将一个事务拆分为两个阶段，先尝试后提交，以实现事务的原子性。

### 故障恢复

完善二阶段提交协议

#### 协调者发生故障

当协调者发生故障后，备用节点称为新的协调者参与进来。如果新上任的协调者像保证正确性，就要完成上一任未完成的任务。分为两种情况：

1. 如果上一任协调者在处理最后一条全局事务中已经完成了第二阶段的所有工作，那么新的协调者自然不需要做任何操作。但如果上一任在发送Prepare后发生故障，此时所有正常处理了Prepare请求的参与者都处于阻塞状态，所需的事务资源也处于锁定状态。此时新上任的协调者需要完成第二阶段的工作。至于新上任的发送Commit还是Rollback需要先询问所有参与者第一阶段执行的情况。

2. 第二种情况是，上一任已经开始了第二阶段的工作，但只部分发送了Commit或Rollback，还有一部分未收到。新上任的协调者在询问所有参与者时，如果有参与者执行了Commit或者Rollback，协调者通知其他参与者执行相同的指令。

#### 部分参与者发生故障

参与者发生故障，新的参与者加入集群后也要继续完成发生故障的参与者未完成的工作。

第一种情况：当故障的参与者完成了第一阶段工作，并回复给协调者之后发生故障，导致没有收到协调者的Commit或Rollback指令，此时，通常是新的参与者主动询问协调者。询问最后一条事务的执行指令，并完成相应工作，并释放资源。

第二种情况：参与者未完成第一阶段工作，协调者因等待参与者超时而发起Rollback请求，通知其他参与者进行事务回滚，并释放事务资源。

这种情况下，新加入的参与者感受不到最后一条事务的存在，自然不需要做额外的工作，也能保持协议的正确性。

### 二阶段的优缺点

简单，易于理解。

同步阻塞、数据不一致、单点问题和脑裂

同步阻塞：二阶段协议的阻塞主要体现在参与者需要协调者的指令才能执行第二阶段的操作。当协调者发生故障的时候，参与者在第一阶段锁定的事务资源无法释放。

数据不一致：在第二阶段，如果因为网络异常而导致一部分参与者收到Commit请求，而另一部分参与者没有收到Commit请求，那么结果将是一部分参与者提交了事务，二零一部分参与者无法提交。

单点问题和脑裂：

- 单点问题：二阶段协议过于依赖协调者。协调者发生故障的时候，整个集群将不可用

- 脑裂：当出现多个协调者的时候，将不能保证二阶段协议的正确性。

### 空回滚和防悬挂

空回滚是指第一阶段，发生网络丢包时，协调者发送的Prepare请求没有送达参与者。根据协调者超时规则，协调者等待超时后将会发送Rollback。如果此时网络恢复，那那些没有处理过第一阶段的工作的参与者将会进行空回滚。

在实现第二阶段提交协议的时候应该特别注意空回滚的情况。能够支持这种场景，而不会抛出客户端无法理解的异常。解决这个问题的常规方案是，由协调者生成一个全局唯一的XID，协调者每次发送请求时都需要携带XID，参与者在第一阶段将XID记录在日志中，在处理第二阶段的请求的时候，如果XID不在日志中则不予理会。

放悬挂：由于网络延迟导致Prepare请求在Rollback之后被参与者收到，在实际场景中，参与者应该拒绝迟来的Prepare请求。但是如何确定收到的Prepare请求是上一个事务还是一个新事务的开始呢？在空回滚的基础上，要拒绝空回滚之后到来的Prepare请求应该怎么办？这种情况就是防悬挂，需要在第二阶段处理之前也记录一条日志，在第一阶段查询该日志。如果查到了就抛弃这条Prepare请求。

## 三阶段提交协议


