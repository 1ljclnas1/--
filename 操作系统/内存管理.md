# 1. 内存虚拟化是什么，有什么目的

- 资源隔离与共享：在不同的进程、应用程序或虚拟机之间隔离内存资源，提高稳定性和安全性

- 易用：简化了内存管理，无需关心物理内存的细节。操作系统负责

- 容错与恢复：可以将虚拟内存状态保存至磁盘，然后在另一台计算机上恢复。

- 内存优化：支持一些内存优化技术，如按需分配、内存去重、内存压缩。

- 进程保护：每个进程都有自己的虚拟地址空间，防止意外或恶意访问。

# 2. 逻辑地址与物理地址的区别

- 逻辑地址：虚拟地址，CPU生成的。在程序执行的时候都是逻辑地址。每个进程都有自己的逻辑地址空间。逻辑地址由操作系统和MMU映射到物理地址。

- 物理地址：实际内存硬件中的地址，全局唯一。

# 3. 操作系统在对内存管理时做了什么

- 内存分配：当一个进程需要内存的时候，操作系统负责分配。通常维护一个内存池，由于追踪可用的内存块。当申请的时候从列表或池中分配合适大小的内存块。

- 地址空间管理：每个进程都有自己的虚拟地址空间。通过MMU将虚拟地址转换为物理地址。

- 内存保护：操作系统确保每个进程的内存空间不被其他进程非法访问。

- 内存回收：当进程终止或释放内存时，操作系统负责回收到空闲内存列表或内存池。

- 页面置换：当物理内存不够用的时候，使用页面置换算法换出一个合适的页面。

- 内存优化：提高资源利用率。如，内存去重（将多个相同内容的内存页面合并为一个），内存压缩（压缩不常用的内存页面以节省空间）和按需分配（只在需要的时候分配内存）

# 4. 讲一讲物理内存与虚拟内存的映射机制

由于分段式内存碎片较多，常采用分页机制，通过MMU和操作系统共同完成：

- 分页机制：虚拟内存和物理内存都被划分为固定大小的单元，称为页。虚拟页的大小与物理页一致，通常为4KB或更大。分页系统的主要目的时将虚拟内存中的页映射到物理内存中的页。

- 页表：是一种数据结构，用于存储虚拟页到物理页的映射关系。每个进程都有自己的页表，由操作系统管理。

- 地址转换：虚拟地址通常由两部分组成：虚拟页号和页内偏移。虚拟页号用于查找页表中相应的物理页号，而页内偏移表示在物理页中的具体位置。
  
  - CPU生成一个虚拟地址
  
  - MMU从虚拟地址中提取页号和页内偏移
  
  - MMU使用VPN在页表中查找对应的物理页号
  
  - MMU将物理页号与页内偏移组合成物理地址
  
  - CPU使用物理地址访问物理内存

- 页面置换和缺页中断：当虚拟页尚未加载到物理内存时，发生页面缺失。这时产生缺页中断，操作系统需要从磁盘或其他存储设备中加载所需的虚拟页，并将其映射到物理内存。为了腾出空间，操作系统可能需要选择一个已加载的页面，将其换出到磁盘。

- 多级页表：用于减少页表大小。通过将虚拟地址空间划分为多个层次来减少页表的大小，每个层次都有自己的页表，只有需要时才会分配

- 快表（TLB）：也被称为转换后援缓冲，是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB将最近使用过的虚拟地址到物理地址的映射存储在高速缓存中，以便快速查找。当MMU需要转换一个虚拟地址时，他会说先检查TLB是否包含所需的映射。如果TLB中存在映射，MMU可以避免访问内存中的页表，从而加速地址转换过程。

- 内存分配策略：按需分配，预取

- 内存共享：允许多个进程访问相同物理内存区域的技术。通过将不同进程的虚拟地址映射到同意物理页，操作系统可以实现内存共享。在共享库、进程间通信和内存去重等场景中非常有用。

# 5. 什么是换页机制

将虚拟内存与物理内存换分成一个个页，从而实现内存虚拟化、提高内存利用率和实现进程隔离。

- 页：通常为4KN或更大

- 页表：用于存储虚拟页和物理页之间的映射关系。每个进程都有自己的页表，可以是多级页表。

- 内存管理单元：负责在CPU访问内存时将虚拟地址转换为物理地址。使用页表完成转换。

- 页面置换算法：当物理内存告急时，使用页面置换算法来确定一个或多个合适的物理页将其换出。

- 缺页中断：当进程试图访问为加载到物理内存的虚拟页时发生。

# 6. 操作系统中的缺页中断？

缺页中断：当进程试图访问为加载到物理内存的虚拟页时发生。

**过程：**

1. 检查虚拟地址是否有效，即是否存在对应的虚拟内存页。无效则返回一个错误

2. 查找一个空闲的物理内存页帧来存储所需的虚拟内存页

3. 如果没有页帧，使用页面置换算法换出一个页面，将其写入磁盘（如果被修改过）。

4. 读取所需的虚拟内存页并将其加载到新分配的物理页帧。

5. 更新页表，将虚拟地址映射到新分配的物理内存页帧

6. 恢复程序执行

**优化策略** 

由于缺页中断过程涉及磁盘读写，因为可以采用一些策略进行优化：

- 缓存与缓冲：使用缓存和缓冲来减少磁盘访问次数。缓存可以暂存最近访问过的数据，提高读取速度。缓冲可以合并多个连续的写操作。

- 预取：一种预测性技术，根据程序的访问模式来预先加载可能被访问的内存页，从而减少缺页中断。

- 页置换算法：为了提高内存利用效率，操作系统使用页置换算法来决定在发生缺页中断物理内存告急时，替换哪个页面。LRU、LFU、时钟算法

- 写回策略和写穿策略：允许操作系统将内存页写回磁盘前缓存修改过的数据，减少磁盘写入次数。写穿要求每次修改内存页立即写回磁盘，确保数据一致性，但增加开销

- 内存压缩：将内存中的空闲空间压缩，从而减少内存碎片，提高内存利用率

> 补充
> 
> **缺页中断发生时的事件顺序**
> 
> 硬件陷入内核，在堆栈中保存程序计数器，将当前指令的各种状态信息保存在特殊的CPU寄存器中；保存通用寄存器和其他易失的信息，一面操作系统破坏；当发生一个缺页中断时，尝试发现需要哪个虚拟页面。通常一个硬件寄存器包含了这个信息，如果没有的话，操作系统必须检索程序计数器，取出这条指令，用软件分析这条指令，看看他在缺页中断时正在做什么；
> 
> 一旦知道了发生缺页中断的虚拟地址，操作系统检查这个地址是否有效，并检查存取与保护是否一致。如果不一致，想进城发出一个信号或者杀掉该进程。如果地址有效且没有保护错误发生，检查是否有空闲页框，如果没有则执行页面置换算法淘换一个页面。
> 
> 如果选择的页框脏了，就安排写回磁盘，并发生一次上下文切换，挂起产生缺页中断的进程，让其他进程运行直至磁盘传输结束。无论如何，该页框被标记为忙，一面因为其他原因被其他进程占用
> 
> 一旦页框干净后，操作系统查找所需页面在磁盘上的地址，通过磁盘操作将其装入。该页面被装入后，产生缺页中断的进程仍被挂起，并且如果有其他可运行的进程，则选择另一个用户进程运行
> 
> 当磁盘中断发生时，表明该页已经被装入，页表已经更新可以反应它的位置，页框被标记为正常状态；
> 
> 恢复发生缺页中断指令以前的状态，程序计数器重新指向这条指令。
> 
> 调度引发缺页中断的进程，操作系统返回调用它的汇编语言程序
> 
> 该程序恢复寄存器和其他状态信息，返回到用户空间继续执行。

# 7. 换页时的抖动是什么？

频繁的产生缺页中断并进行换页的现象。

- 过高的内存需求

- 不恰当的内存分配：操作系统没有合理的而非你陪内存资源给各个进程，导致个别进程内存资源不够，产生频繁的换入换出

- 不合理的页面置换算法：不能准确的预测进程将访问哪些内存页面，可能会导致频繁的换入换出

解决办法：

- 内存管理优化：采用更先进的内存管理技术和页置换算法

- 资源控制：可以对进程进行资源控制，限制其内存使用量，防止过高的内存需求导致抖动

- 内存扩展：增加物理内存容量

- 调整工作负载

- 使用交换空间：可以减轻抖动现象。但速度较慢

# 8. 进程的内存分布？

- 代码区

- 已初始化数据区

- 未初始化数据区

- 堆区

- 栈区

- 内核空间

# 9. 堆上建立对象快，还是栈上建立对象快

栈上建立快

编译的时候就决定好了，而堆上面需要申请，这里会慢，如果走了慢速路径会更慢。

运行的时候由于栈上面的都是连续空间，所以局部性更好，运行效率会更高。

栈还可以减少碎片化，碎片化分为外部碎片和内部碎片，外部碎片就是内存分配算法不可分配的，内部是分配后不能被利用的，对于Linux来说，内存是以页为单位的，想slab和用户空间的slab都是先申请一定空间然后使用。因此有很多的分配思路，但这些思路基本上围绕两个标准，如何碎片最少，如何速度最快

对于外部碎片就是使用Buddy思想， 首先提前把内存分为不同大小的内存块，然后这些块都是2的指数倍，以order来表示每一层的块大小，2的order次幂。Buddy体现在一个大的内存块可以被一分为二，而一个内存块的地址异或块大小就可以得到另一块伙伴的地址，只有互为伙伴的内存块才可以相互合并。在zone中存储了order个链表，每一个链表存同样块大小的内存块，当一个链表的块不够用了之后，从上级链表中拿一半使用，如果还有剩余的话就按照大小往下挂载，内存在释放的时候会主动判断是否可以与空闲链表中的页面合并，可以的话，就合并并交给上一阶的链表。

释放对象：栈上自动释放，堆上需要手动释放

# 10. 常见的内存分配方式？

静态：存储在文件的数据段，包括初始化的和未初始化的全局变量与静态变量

栈上：局部变量、函数参数和返回地址，使用后进先出的方式进行分配和释放。栈内存分配较快，但受大小限制。且对象的生命周期受到作用域限制

堆上：...又是那一大堆（内核）。用户空间的：dlmalloc（单线程，并发不大的），并行优化的dlmalloc即ptmalloc，glibc，tcmalloc等。

# 11. 页置换算法有哪些

LRU（最近最少使用）

OPRA(最佳置换算法)

FIFO（先进先出算法）

CPRA（时钟置换算法）

RPRA（随机置换算法）

# 12. 如果64位电脑是4G内存，要申请80G可以申请么？32位呢？

# 13. malloc怎么实现的？

# 14. mmap怎么实现的

# 15 共享内存如何实现的

# 笔记

## 1. 地址空间

Intel在实现64位CPU时，只使用了48位有效寻址位数，低48位。内核空间前16位是1，用户空间前6位是0。

中间有个大空洞主要是因为这16位。

一个用户空间的程序主要包括两部分**ELF部分**和**从内核申请的内存**。

加载ELF部分主要是加载ELF的segment段，一般有2-4个LOAD类型的segment最后一个中包括.bss sectiion(用于存储未初始化的全局变量和静态变量)。加载ELF之后需要加载linker和以来的so库，这些都是通过mmap系统调用从内核中申请的。

由于32位只能看见4GB内存，因此产生了对动态映射的需求。在Linux中，由于CPU可见的3GB给了用户程序，内核只剩1GB空间，而内核可以访问的存储的映射都在这1GB中，所以必须要有动态映射。简单说就是：当需要一个空白内存页时，动态地将某个物理内存映射到一个地址，换下已经映射过的物理地址，重新映射新的物理地址到这个线性地址。

由于现在系统不止跑一两个程序，安装别人发布的程序又是比较危险的，因此每个程序在可见的地址空间隔离是有必要的，于是有了虚拟的程序地址空间。

高效的分配和回收内存是重要的。在实际需求中，用户可以申请内存，但不一定使用，内核也可以为用户预留内存，只是在真正使用的时候才分配，这种机制就叫做**over_commit**。

Linux内核会使用大量的空间来缓存磁盘中的文件，这部分内存几乎用掉了所有的物理内存。当用户程序对物理内存有需求的时候，Linux会回收这一部分。表面看可用内存为0，但实际申请是可以的。

Linux内核内存以页为单位，但是整体被组织为**zone（区域）** ，一共有3个zone: DMA、Normal、High。编译内核时关闭DMA zone。可以有效加速内存回收的速度。

Linux引入高端内存，来解决内核线性地址空间不够用的问题。把1GB空间划分为两部分：小于896MB的是低端内存，大于896MB的是高端内存。高端内存用于映射大于896MB的物理地址空间，需要MMU通过TLB建立动态地映射关系。

**高端内存**：有三种映射方式：临时映射空间，长久映射空间，非连续映射地址空间。

1. 临时映射空间
   
   内核空间中的一组保留虚拟页面空间，位于线性地址末尾，用于特定用途
   
   接口函数kmap_atomic，kunmap_atomic，

2. 长久映射空间
   
   预留的线性地址空间，也是访问高内存的一种手段。逐渐被临时映射空间替代。
   
   接口函数kmap

3. 非连续映射空间
   
   适用于不频繁申请释放内存的情况，这样不会频繁的修改内核页表：映射设备的IO空间，为内核模块分配空间，为交换区分配空间。
   
   接口函数，vmalloc

## 2. 寻址

### 64位寻址

#### (1) Intel CPU硬件寻址

Intel CPU有四种寻址方式：32位寻址，PAE寻址，四级寻址，五级寻址

32位和PAE只用于保护模式下

四级和五级用于IA-32E模式下，分为两个子模式一是兼容模式，一是64位模式

兼容模式下，不管是五级还是四级63到32位都是0 。 

64位模式下四级只有47-0是用于寻址的，五级是56-0 57位用于寻址，每一级9位加上最后12位页偏移。

对于四级寻址来说，四个索引就是四级寻址，最后一部分是页内偏移，而当使用2MB大页的时候最后一级的也索引地址直接与页内偏移融合，变为了三级索引，1GB大页就再减少一级。

#### (2) Linux软件寻址过程

在Linux的软件定义层面四级寻址中，每一级的页寻址都是9位。从高到底分为是PGD, PUD, PMD, PT。支持2MB和1GB的大页与硬件一样。

CR3指向第一级PGD表的内存地址，根据CR3的47-39位找到对应的PGD条目，其中有存储下一级PUD表的内存地址，以此类推找到最后一级PT条目里面存储了真实物理地址的47-12位地址。线性地址的11-0位的页内偏移就直接作为物理页的页内寻址偏移。

#### (3) Linux寻址系统初始化

纯粹的内核空间的线程是共享地址空间的，相当于整个内核是一个进程。

#### (4) Linux下进程的寻址数据结构

每个进程有自己独立的内存空间，进程地址空间的隔离是通过每个进程不同的多级寻址表实现的，也就是MMU。

fork函数会调用同文件下的mm_init函数来初始化新创建的进程的内存数据结构，mm_init调用mm_alloc_pgd函数， 初始化寻址的第一级PGD表。实际的初始化函数是/arch/x86/mm/pgtable.c的pgd_alloc函数，它完成pgd页表的内存申请和初始化。

### Intel的硬件四级寻址过程

PML4->PDPT->PD->PT

#### 1).  页的权限控制

每一级都有权限的设置

#### 2). 页性能控制

多个MSR寄存器限定多块内存的不同的缓存访问方式，不同的缓存访问方式对应不同的性能用途。

#### 3). 页的状态控制

最后一级的PTE的定义（PT的条目）很多地方与上级有区别，比如第5位access和第6位dirty，物理页被映射后access被置为1，数据发生修改后dirty被置为1.、

#### 4). 页缓存

除了TLB还有一个与页的四级查询结果的缓存相关就是page-structure cache。

首先看一个叫做PCID的技术，它是一个12位的寄存器位，位于 CR3上 （与PML4在同一个寄存器上），代表一个进程的ID。PCID的引入可以减少进程上下文切换时刷TLB和TLB重新学习的开销。每个TLB条目都包含了一个进程ID标志，由于PCID不一样所以并不会混淆。

Intel CPU还直接定义了Task这种元素，CPU定义的Task包含两部分一是Task的上下文（code、data、stack等不同的内存空间位置），而是TSS（Task-State Segment），代表进程的描述符。这个硬件的设计软件层面的struct task设计的基本概念是一致的。TSS是一个存储在页中的表，基地址同样在CR3中。

在Intel的CPU上，运行任何复杂的系统都需要至少定义一个Task，没有Task就没有执行上下文，所有Task之间是相互关联的，形成了一个大链表，这在Linux内核中的struct task也是如此。

但从Linux2.4开始，就不再使用Intel的Task机制，而是采用一个CPU核上的所有进程共用一个TSS。因为Intel的提供的TSS数量有上限，最多8192个，这对于Linux来说是不能接受的。

TSS中有很多域，里面存储的就是常说的进程上下文，包括寄存器的线程和最重要的EIP寄存器的值。EIP代表当前执行的代码位置，如果这个被调度的Task还没有被执行，EIP就会指向这个Task的code内存地址的第一个位置。

CR3的内容存储在TSS中，随着Task的切换而重新加载CR3。

### 操作系统的页状态和权限控制

没看懂

### 页框回收算法（PFRA）

太过深入，后面有简单的。

### 段寄存器

...

## 3. 堆内存管理

### Buddy思想与Slab思想

内存在底层是以页为单位的，上层的分配器如slab，用户空间的malloc等都是在后台现申请了足够的页之后再对用户进行分配。这样后台关于如何申请页就有很多思路，这些思路主要围绕两个标准展开：**如何速度最快**和**如何碎片最少**

一般对于页维度的分配都是用Buddy思想，对应内核的伙伴系统，用于页以上大小的内存分配。

Buddy的核心思想是把内存提前分为大小不同的一系列内存块，当申请内存时返回最贴近需求内存大小的内存块，没有合适内存大小的时候就将大内存块拆分成多个相对匹配的内存块。每个内存块大小都会是2的指数倍。

一个Buddy系统定义一个order的概念，order代表每一个内存块的实际大小。首先定义最小的内存块大小，比如64KB，那么0级的order就是64KB，1级的是128KM，2级256KB，最大假设是5就是2048KB.也就是说，Buddy系统需要定义两个值：

- 最小内存块大小

- 最大order的值

由于每个内存块都是2的指数倍，因此每次切割为大小相等的两个更小的order内存块，这样相当于能够将可分配内存完全切割成可分配的内存块，也可以叫做**外部碎片最小**

内存分配算法的一个重要指标就是碎片程度，当内存持续分配时，内存被浪费掉、无法再次被分配的程度。例如，大量的小空间内存的频繁申请与释放，容易造成在连续的内存块上打洞，很难找到相对大的连续内存块分配。

内存碎片包括**外部碎片**和**内部碎片**，外部碎片是内存分配算法本身不可被分配的内存，内部碎片是已经被分配出去的却不能被利用的内存空间。

Buddy思想是广泛用于解决外部内存碎片的，同时它会带来大量的内部碎片，因此与Slab这种小内存管理思想结合用于解决内部碎片的问题。

Buddy叫做一个伙伴，同时一个内存块必然有一个伙伴内存块，这个伙伴就是另外一个大小相等的内存块，由一个内存块一分为二切割而来，也只有伙伴内存块可以合并。同步不断合并组成大内存块的过程叫做compaction。用一个内存块的地址与内存块的大小进行异或就能得到伙伴内存块的地址。

Slab机制通常被认为是一个拟内存池机制。

#### 1. Linux内核的Buddy系统

Linux内存划分为多个zone，一般有DMA, Noemal， HighMemory三个，逐渐在成为一个（Normal）

不同NUMA节点的不同zone划分仍有很大意义，内存申请总是倾向于距离当前逻辑所在的cpu更近的zone进行申请。struct page * alloc_page(unsigned int gfp_mak)函数是从Buddy系统申请内存的入口gfp_mask可以指名为__GFP_DMA、__GFP_HIGHMEM等尽量从DMA或高端内存分配。

每一个页对应一个page结构体，一个zone包含这个cone下所有可用的page页

```cpp
struct zone{
    struct free_area        free_area[MAX_ORDER];
};
struct free_area{
    struct list_head        free_list[MIGRATE_TYPES];
    unsigned long           nr_free;
};
```

free_list就是这些内存块的链表，链表的链是page，由于每个内存块可能包含多个page，所以free_list实际上是以PAGE_SIZE为单位组织起来的，只是多个page会连续起来组成一块连续的物理内存

不同大小的连续页面会挂载在不同的链表上，当低阶连续页面不足时，就会从比它高一阶的链表中切出一般来使用。如果使用的一半还有剩余，就按照大小匹配加入到其他更低阶的order链表中。当被划走的内存释放时会主动判断该内存的地址与空闲链表的页面是否可以合并，也就是判断是否为伙伴，如果可以合并，就会被合并起来移交到高一阶链表。

Linux内核有个特点就是尽可能的用上所有的内存，用户没用到的内存也尽量来进行磁盘文件的缓存，所以Linux的内存使用率总是一个较高的程度，这意味着进入慢速路径的概率比较高。而慢速路径会阻塞申请内存的逻辑，对性能体验很不好，所以要尽可能地不进入慢速路径，这可以通过内存回收线程执行，其检测到内存使用达到一定程度就会启用内存回收算法来回收内存。

需要平衡内存回收算法的执行频率和内存申请的频率。如果回收过于频繁会导致缓存命中下降，如果回收过少会导致进入慢速路径概率增加。

### 内存回收（PFRA）

由于Linux内核的思路是所有内存都要尽量被使用，所以内存回收是非常频繁的，并且只要用户不释放们就无法从应用的内存中回收资源，除非OOM。

内存页有命名页和匿名页两种，命名页对应在内存中缓存的文件，这部分是重点回收的。

有三个水位线max low min，低于low的时候就会唤醒kswapd线程，如果kswapd线程回收的不如上层申请的快，导致水位线降低至min了，这时会触发内存回收机制，而这种方式会阻塞应用程序。

页框算法会保存一定的空闲页框，以便内核可以从缺少内存的情形中恢复过来、

PFRA的目标是获得页框并使之空闲。PFRA按照页框所包含的内容，以不同的方式处理页框。页框分为**不可回收页框、可交换页、可同步页、可回收**页四种。其中PFRA可以处理不可回收页以外的页。

内核检查页面回收分为周期性检查和内存不足时的阻塞检查。周期性检查由kswapd线程完成。

如果操作系统再进行了内存回收后（min以下触发的那个）仍然无法回收到足够的内存，这个时候就会调用OOM killer。它会从系统中挑选一个最合适的进程杀死它。同时释放这个进程所占用的所有页面。打分方法可以在/proc中调整

zone在其区域描述符中定义了这三个水位线。
