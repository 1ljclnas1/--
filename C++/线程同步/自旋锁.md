[深入理解Linux自旋锁(1.0)_linux 自旋锁 mcs 头节点_城中之城的博客-CSDN博客](https://blog.csdn.net/orangeboyye/article/details/125488951)



忙等待

根据自旋锁的逻辑，自旋锁的临界区是不能休眠的。

自旋锁一开始简单，但是有公平性的问题，所以有了**票号自旋锁**，后来又由于票号自旋锁有很大的性能问题，所以先有了**MCS自旋锁**，虽然解决了性能问题，但是改变了自旋锁的接口，没有办法代替自旋锁，有改造除了**队列自旋锁**

# 原始自旋锁

linux-src/include/linux/spinlock_types.h

```c
typedef struct {
    raw_spinlock_t raw_lock;
} spinlock_t;
```

linux-src/include/asm-x86/spinlock_types.h

```c
typedef struct {
    unsigned int slock;
} raw_spinlock_t;
```

本质上是一个无符号整数。

自旋锁的定义和初始化分为静态和动态两种。静态是指自旋锁在编译的时候分配好了空间、数据初始化好了，这种一般是全局自旋锁变量。

动态是指自旋锁是在运行时去创建然后用函数去初始化的。这种情况一般是自旋锁内嵌在某个结构体里面，随着结构体创建而创建，需要用函数去初始化以下

静态定义与初始化如下

linux-src/include/linux/spinlock_types.h

```c
#define DEFINE_SPINLOCK(x)    spinlock_t x = __SPIN_LOCK_UNLOCKED(x)

#define __SPIN_LOCK_UNLOCKED(lockname) \
    (spinlock_t)    {    .raw_lock = __RAW_SPIN_LOCK_UNLOCKED}
```

linux-src/include/asm-x86/spinlock_types.h

```c
#define __RAW_SPIN_LOCK_UNLOCKED    { 1 }
```

自旋锁的动态初始化如下：  
linux-src/include/linux/spinlock.h

```c
# define spin_lock_init(lock)                    \
    do { *(lock) = SPIN_LOCK_UNLOCKED; } while (0)
```

## 加锁操作

linux-src/include/linux/spinlock.h

```c
#define spin_lock(lock)            _spin_lock(lock)
```

linux-src/kernel/spinlock.c

```c
void __lockfunc _spin_lock(spinlock_t *lock)
{
    preempt_disable();
    LOCK_CONTENDED(lock, _raw_spin_trylock, _raw_spin_lock);
}
```

linux-src/include/linux/lockdep.h

```c
#define LOCK_CONTENDED(_lock, try, lock) \
    lock(_lock)
```

linux-src/include/linux/spinlock.h

```c
# define _raw_spin_lock(lock)        __raw_spin_lock(&(lock)->raw_lock)
```

linux-src/include/asm-x86/spinlock_32.h

```c
static inline void __raw_spin_lock(raw_spinlock_t *lock)
{    asm volatile("\n1:\t"
             LOCK_PREFIX " ; decb %0\n\t"
             "jns 3f\n"
             "2:\t"
             "rep;nop\n\t"
             "cmpb $0,%0\n\t"
             "jle 2b\n\t"
             "jmp 1b\n"
             "3:\n\t"
             : "+m" (lock->slock) : : "memory");
}
```

linux-src/include/asm-x86/spinlock_64.h

```c
static inline void __raw_spin_lock(raw_spinlock_t *lock)
{
    asm volatile(
        "\n1:\t"
        LOCK_PREFIX " ; decl %0\n\t"
        "jns 2f\n"
        "3:\n"
        "rep;nop\n\t"
        "cmpl $0,%0\n\t"
        "jle 3b\n\t"
        "jmp 1b\n"
        "2:\t" : "=m" (lock->slock) : : "memory");
}
```

spin_lock的最终实现是_raw_spin_lock, 是在架构代码里面，分32位和64位两种，用的都是内嵌汇编代码

## 解锁操作

linux-src/include/linux/spinlock.h

```c
#define spin_unlock(lock)        _spin_unlock(lock)
```

linux-src/kernel/spinlock.c

```c
void __lockfunc _spin_unlock(spinlock_t *lock)
{
    _raw_spin_unlock(lock);
    preempt_enable();
}
```

linux-src/include/linux/spinlock.h

```c
# define _raw_spin_unlock(lock)        __raw_spin_unlock(&(lock)->raw_lock)
```

linux-src/include/asm-x86/spinlock_32.h

```c
static inline void __raw_spin_unlock(raw_spinlock_t *lock)
{
    asm volatile("movb $1,%0" : "+m" (lock->slock) :: "memory");
}
```

linux-src/include/asm-x86/spinlock_64.h

```c
static inline void __raw_spin_unlock(raw_spinlock_t *lock)
{
    asm volatile("movl $1,%0" :"=m" (lock->slock) :: "memory");
}
```

# 票号自旋锁

解决公平性问题

把原来的自旋锁的整型变量拆为两部分，一部分owner，代表当前正在办业务的票号，另一部分next，代表下一个人取号的号码，每次枷锁的时候，先取号，定义一个局部变量int ticket = next++,自己去的是next的值，然后next++，然后不停的比较自己的ticket和owner的值，如果不相等就一致比较，直到相等为止。解锁就是把owner加1，此时如果有其他线程自旋，他发现owner加1之后和自己的ticket相等了就结束自旋，加锁成功。

# MCS自旋锁

虽然票号自旋锁解决了公平问题，但是，当锁竞争激烈的时候，会导致缓存颠簸，严重降低CPU的性能。为解决这个问题，有了MCS自旋锁。把所有排队等锁的线程放到一个队列上，每个线程都自旋自己的节点，这样就不会有缓存颠簸的问题了，而且还是公平锁。所本身是个指针，指向排队队列的末尾，每个申请加锁的线程都要自己创建一个锁节点，然后把自己放到这个队列的末尾，并让锁指针只想自己，最后在自己的节点上自旋。当线程解锁时，kankannext是否为空，不为空就把next节点设置为加锁状态。

# 队列自旋锁

MCS的很大问题就是跟以前的锁不兼容，而且体积大。所以又开发了队列自旋锁。优化原理是：一个系统最多同时有MR_CPU个自旋锁在运行，所以没必要每个枷锁线程都自己分配一个锁节点，我们在系统全局预分配NR_CPU个锁节点就可以了，哪个CPU上要执行自旋锁，就去用对应的锁节点就可以了。这是对于只有线程的情况，实际上还有软中断、硬中断、NMI，它们后者可以抢占前者，都能抢占线程，所以整个系统实际上总共需要NR_CPU*4个锁节点就够了。队列自旋锁还对只有两个线程强所得情况锁了优化，不会使用MCS的排队逻辑

下面我们用一个比喻来说一下队列自旋锁的总体逻辑。我们把锁的位置比作皇位，抢到皇位就是加锁成功就可以进入临界区了。第一个来抢锁的人就是直接抢锁成功，抢到皇位。第二个来抢锁的人发现皇位已经被抢了，退而求其次，抢占太子位，然后一直自旋皇位，一旦皇帝驾崩让出皇位，自己就立马抢占皇位。第三个来抢锁的人发现皇位和太子位都被抢了，没有办法只能去抢太孙的位置，然后同时自旋太子位和皇位。当皇位空缺的时候，太子会替补到皇位，此时太子位空缺，但是太孙并不会去抢占太子位，他还待在太孙位上，直到太子位和皇位同时空缺了，他才会一步到位，直接从太孙位上登基为皇帝。第四个人来了发现皇位、太子位、太孙位都被抢了，就只能占个皇孙位了，从第四个人开始包括后面来的每个人都是皇孙，所有皇孙依次排好队等待进位成太孙。太孙其实也算是皇孙，太孙是第一皇孙，其它的都是普通皇孙。皇孙也在自旋，只不过皇孙是在自己家门口自旋，他一直在等待上一任太孙到自己家门口叫自己。太孙发现皇位和太子位同时空缺了之后就会去继承皇帝位，同时去通知第二皇孙，太孙位空出来了，你可以来当太孙了。然后第二皇孙就变成太孙了，变成太孙之后他也是去同时自旋太子位和皇位。当他也登基称帝之后他也会去通知后面的第二皇孙来进位太孙位。然后就一直继续这样的逻辑，后面来的每个人只要发现有太孙存在就只能去占个皇孙位来排队，然后在自己家门口自旋。在这个过程中太子位是一直空缺的。除非最后一个太孙登基称帝之后发现没有皇孙了，此时就没有人进位成太孙了，如果此时再来了人抢位子，而皇位还被占着，他才会去抢太子位。

前面说的逻辑比较复杂，我们再来总结一下，当只有两个人抢锁时，一个占据皇帝位也就是抢锁成功，一个人占据太子位，同时自旋皇位。也就是说同时抢锁的人小于等于两人时不会使用排队机制。第三人来抢锁的话就会启动排队机制，他排在队列的第一位，是第一皇孙，也叫太孙，之后来的人都是普通皇孙，要依次排队。皇孙都是在自己家门口自旋自己，等待前太孙来通知自己进位为太孙。太孙的逻辑是最为复杂的，他要同时自旋太子位和皇位，只有当太子位和皇位都空缺时，太孙才会一步到位登基称帝，然后通知第二皇孙进位为太孙。解锁的逻辑很简单，只需要把皇位设为0就可以了，什么都不用管，因为太子、太孙他们自己会自旋皇位。

队列自旋锁的实现是把原先的锁变量int分为三部分，一个locked字节，对应我们所说的皇位，一个pending字节，对应我们所说的太子位，一个tail双字节，它指向皇孙队列的末尾，皇孙队列的队首是太孙。tail不是个指针，而是逻辑指针，它是通过编码的方式指向队尾皇孙的。每个皇孙都对应一个锁节点，系统预先分配了NR_CPU * 4个锁节点，NR_CPU代表1个CPU 1个，为什么乘以4呢，因为1个CPU上最多可以同时嵌套4个执行流，分别是线程、软中断、硬中断、非屏蔽中断。tail有16位，分两部分编码，其中2位用来编码是哪个执行流，14位用来编码CPU index。CPU编码时要加1，因为CPU index从0开始，而tail等于0有特殊含义，代表的是空指针，也就是没有皇孙来竞争，所以要加上1做区分。当一个线程(执行流)来争锁时，如果太子位被抢了或者已经有太孙了，自己就需要加入皇孙队列，加入皇孙队列的方法就是根据自己所在的CPU index 和自己的执行流等级去拿一个锁节点，把这个锁节点加入到队列中去，并自旋这个锁节点。


# 自旋锁的使用

## 使用场景

有的地方说临界区小于1000个指令或100行代码、其次，临界区不能休眠。如果临界区内某些函数调用可能会阻塞，那就不能使用自旋锁。

## 自旋锁与禁用伪并发的配合使用

自旋锁可以防止两个CPU同时进入临界区，但是不能阻止被更高级的执行流所抢占、

所以当两个关联临界区在不同类型的执行流的时候，只是用自旋锁是不够的，低级执行流还得禁止高级执行流的抢占。由于NMI是不可禁止的，而NMI发生概率很低，所以一般不考虑NMI。

## raw_spin_lock的使用问题

可能很多人在看到内核代码时会感到有些奇怪，为啥有些地方用的是spinlock_t，有些地方用的却是raw_spinlock_t？raw_spinlock_t不是spinlock_t的实现细节吗，我们不是应该只使用接口性的东西，而不要使用实现性的东西吗？再仔细看spinlock_t和raw_spinlock_t的实质逻辑，好像也没啥区别啊？要回答这个问题，我们就要先从一件事情谈起，PREEMPT_RT补丁。

什么是PREEMPT_RT补丁，什么是实时性？实时性是指一个系统对外部事件响应的及时性。很多嵌入式系统的OS都是实时OS，它们可以快速地对外部事件进行响应。这倒不是因为它们有多厉害，而是因为嵌入式系统都比较简单，它们面临的环境比较简单，要做的事情也比较简单，所以能做到及时性。而Linux是一个通用操作系统内核，通用这个词就代表Linux要面临很多情况，处理很多问题，所以就很难做到及时性。做到及时性最根本的一点就是要及时处理中断，因为中断代表的就是外部事件。但是在Linux内核里，有很多需要同步的地方都会禁用中断，这就导致中断不能及时响应。Linux在处理中断的时候也会禁用中断，Linux在这方面已经想了很多办法来解决，比如尽可能地缩小中断处理程序，把事情尽量都放到软中断或者线程里面去做。当很多中断处理的事情都被放到线程中去执行了，我们又面临着另外一个问题，如何尽快地让这些线程去抢占CPU立马获得执行。当一个非常不紧急的线程正好执行到自旋锁的临界区时，我们的非常着急的中断处理线程想获得CPU却没有办法，因为自旋锁的临界区不能休眠也就是说不可抢占，我们只能干等着。因此把自旋锁变得可休眠就成为了提高Linux的实时性的重要方法。为此Ingo Molnar等人开发了一个项目PREEMPT_RT补丁，专门来提高Linux的实时性。其中一个很重要的方法就是把自旋锁替换为可休眠锁。但是有些临界区是确实不能休眠的，那怎么办呢？这些临界区就用raw_spinlock_t，raw_spinlock_t还保持原来的自旋语义，不会休眠。到目前为止(内核版本5.15.28)，PREEMPT_RT补丁还没有合入标准内核，所以目前的标准内核里raw_spinlock_t和spinlock_t效果是一样的。但是大家在内核编程的时候还是要尽量使用spinlock_t，除非你的临界区真的不能休眠，才去使用raw_spinlock_t。

