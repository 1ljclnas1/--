# 6. 数据分区

面对海量数据集通常要进行分区

每一条数据只属于某个特定分区。实现方法有多种。实际上每个分区都可以视为一个完整的小型数据库。

采用数据分区的主要目的是提高可扩展性。不同的分区可以放在一个无共享集群的不同节点上。

## 数据分区与复制

分区通常与复制结合使用，即每个分区在多个节点都存在副本。这意味着某条记录属于特定分区，而同样的内容会保存在不同节点上以提高系统可用性。TinyKV的Region就是这样

## 键-值数据的分区

如何确定那些记录放在哪些节点上呢？

分区的主要目标是将数据和查询负载均匀分布在所有节点上。如果节点平均分担负载，那么理论上10个节点应该能够处理10倍的数据量和10倍于单个节点的读写吞吐量（忽略复制）。

而分区不均匀就会导致倾斜，倾斜会导致性能下降甚至引起雪崩。

避免热点最简单的就是随机分配，但是这样就导致查询的时候要并行查询所有节点

## 基于关键字区间分区

每个分区分配一段关键字区间。这样就知道在那个节点上了

关键字区间段不一定均匀，因为数据本身可能就不是均匀的。

但是基于关键字的区间区分有一个缺点：当关键字是时间戳的时候，可能会造成某一段时间内的写都压在一个节点（Group）上。

因此为了避免这种现象，可以在时间戳前面加一些前缀。

## 基于关键字哈希值分区

对于上述数据倾斜与热点问题，很多系统使用基于关键字哈希值的方式来分区。

数据分区的哈希函数比较注重无偏性。且哈希种子应该是确定的。

但是这样会丧失良好的区间查询特性。从而进行区间查询的时候进行并行查询。

### 负载倾斜与热点

基于哈希的方法可以有效减轻热点，但是一个极端情况就是某个关键字是热点数据。

## 分区与二级索引

#### 基于文档分区的二级索引

每个分区维护一个自己的二级索引表

显著的读放大

#### 基于词条的二级索引分区

每个分区维护全局的部分二级索引表

显著的写放大

实践中，二级索引的更新往往是异步的。

## 分区再平衡

随着时间推移，数据库可能会有一些变化：

- 查询压力增加，需要更多CPU

- 数据规模增加，需要更多磁盘和内存

- 节点出现故障，需要其他机器接管节点

所有的变化都要求数据从一个节点迁移到另一个节点。这个**迁移负载的过程就是再平衡**

分区再平衡之后要满足：

- 数据均匀

- 可用性，迁移的时候可以读写

- 避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘IO

### 动态再平衡策略

#### 固定数量的分区

先分成大量的区，一个节点有好多区，然后增加节点后就是从每个节点上面匀走几个，而不会出现大面积转移。

#### 动态分区

当分区的数据增长超过一个可配的参数阈值，他就拆分为两个分区，每个承担一半。相反，如果大量数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区合并。TinyKV是这种

#### 按节点比例分区

刚才的两种方式，动态分区是分区的数量与数据集大小成正比，对于固定数量的分区，每个分区的大小跟数据集大小成正比。

第三种方式就是使分区数与集群节点数成正比关系。换句话说，每个节点具有固定数量的分区。

### 自动与手动再平衡操作

动态平衡的一个重点就是：自动或者手动

自动再平衡和自动故障检测结合可能会有风险。

## 请求路由

典型的服务发现问题，

客户端如何感知应该向那个节点发送请求。

有几种不同的处理策略：

- 允许客户端链接任意的节点。如果节点不能处理则交给下一个（循环式的负载均衡器）

- 将所有客户端的请求都发送到一个路由曾，由后者将请求转发到对应的分区节点。

- 客户端感知分区和节点分配关系。此时，客户端可以连接到目标节点。

不管什么方式，其核心都是：**作出路由决策的组件怎么知道分区和节点的对应关系及其变化的**

### 并行查询执行

对于大规模并行处理（MPP）查询类型很复杂，MPP查询优化器会将复杂的查询分解为许多执行阶段和分区，以便再集群的不同节点上并行执行。尤其是在设计全表扫描。

## 小结

如果数据量太大，单点存储与性能就会成为瓶颈，就要进行分区。目的是通过多台机器均匀分布数据和查询负载，避免出现热点。这需要合适的数据分区方案，再节点添加或者删除的时候重新动态平衡分区。

两种主要的分区方法：

- 基于关键字区间分区

- 基于关键字哈希分区

二级索引也需要分区：

- 基于文档来区分二级索引（本地）

- 基于词条来区分二级索引（全局）


