# Paxos-分布式共识算法

目前公认的解决分布式公式问题最有效的算法之一。

Paxos解决了在分布式系统中如何使某一个值（提案指令）在集群中达成共识的问题。简化了分布式环境的复杂性，是一组成员可以虚拟为一个成员向客户端提供服务。Paxos的另一个使命就是在不可靠的环境中依旧保持算法的正常运行，这称为容错。

## Paxos的诞生

二阶段、三阶段是强一致性算法，而大多数场景不需要100%强一致性算法，相反，我们期望当一部分不能正常工作时，整个集群依旧可以工作量高，并保证数据的正确性。例如，在实现多副本的同步中，我们希望能允许部分副本同步失败，而不影响其他副本进行同步。

二阶段和三阶段的另一个问题就是太过于依赖协调者，这将导致性能瓶颈依赖于但成员，以及网络分区导致的脑裂问题。这些都是在分布式环境中难以解决的痛点。

lamport在1998年以Paxos小岛故事为背景，讲述了Paxos算法，但是这种方式并不为人所接受，2001年Lamport以Paxos Made Simple为题，重新发表论文，用通俗易懂的文字从科研角度触发对Paxos算法进行了严谨的解释，之后Paxos算法的追随者变得越来越多。

## 初探Paxos

先了解整个Paxos的运行过程，在了解推导过程。

### 基本概念

- 容错：在系统运行的过程中对故障的容忍程度。在分布式环境中，经常会出现成员故障、网络分区和网络丢包等问题，分布式容错是指在允许发生这些问题的情况下，系统依然可以正常工作。

- 共识：在对等的成员集合中，让每个成员都认可某一个值，其与一致稍有差别。一致要求每个成员的数据完全相同；而共识并不要求数据完全相同，只要求客户端从人以一名成员处获取的值是相同的即可。

例如·，由A,B两个客户端，都对共识系统中的X进行赋值。A需要设置X=1，B需要设置X=2，那么最终让A和B从共识系统中都获得同一个值（X=1或X=2）的结果就是达成共识。

- 多数派：多数派思想串联了整个协商过程。多数派是指一个集群中超过一半以上的成员组成的集合，即成员个数大于$\lfloor N/2 \rfloor + 1$ （N为成员总数）的集合。

多数派的设定可以保证安全的情况下有效的提高容错性。

- Instance：将其看作一个个单调递增的存储列表更容易理解，它用于存储达成共识后的提案。随着Paxos运行时间的增加，这个列表会变得无限长。在协商发生冲突的时候可能不会由任何提案达成共识，因此这个列表是允许存在空洞的。通常会在空洞的Instance上再运行一轮Paxos，使用默认值Noop来填充。

在Lamport论文中提到，在一个Instance上选择一个提案需要进行多轮RPC消息交互，这种方式过于保守和低效。为了解决这个问题，Lamport提出了Multi Paxos，即在一轮协商过程中多个Instance选择多个提案的优化方案。为了区分优化前和优化后的算法，前者称为Basic Paxos后者称为Multi Paxos。

在论文中Lamport仅给出了Multi Paxos关键部分的实现，对于细节方面，却留下了无限的想象空间。由此衍生出大量的过度解读，出现了不同版本的Multi Paxos实现，但是他们的整体思路都是围绕如何优化消息交互次数和Leader选举展开的。

- 提案编号：指一个单调递增的整数，它标识着一轮协商，提案协商之前需要生成一个全局唯一的提案编号。在Basix Paxos中，一轮协商只会存在一个Instance上达成共识，因此在没有冲突的情况下提案编号和Instance是同步递增的；而在Multi Paxos中，一个提案编号可能应用在多个Instance上。

另外，Paxos中还有很多意思相近的词：

- 提案：由提案编号和提案指令组成的实体。提案编号标识该提案所处的协商轮次，提案指令是指需要达成共识的内容，它可以是一个值或一个指令等。有些地方也习惯吧提案指令称为决议。

- 通过、批准、选择：他们都表示Acceptor同意某一请求或提案。

- 角色：Proposer（提案者）、Acceptor（接收者）、Learner（学习者）。

- 阶段：Prepare阶段、Accept阶段和Learn阶段

### 角色

#### 1. Proposer

整个算法的发起者，他驱动协商的进程，相当于会议的主持人，向所有参会人员公布提案，发起投票并统计投票。

再Paxos宣发中Proposer的主要工作是驱动算法的运转。Proposer在收到客户端的请求后将其封装为一个提案（Proposal），并将该提案发送给所有接受者，根据接受者的相应情况，驱动算法决定是否需要继续往下运行。

#### 2. Acceptor

提案的真正决策者，相当于会议的参会人员，当参会人员收到会议主持人的提案后，需要向主持人表决自己是否支持该提案。

在Paxos算法中，Acceptor的主要工作是对提案进行抉择，它在收到Proposer发来的ti'an后，根据预先约定的规则对提案进行投票，向Proposer反馈自己的投票结果。

#### 3. Learner

Learner不参与提案的发送和决策，只是被动的接受提案选定的结果。当一个提议被选择后，会议将达成的提议公之于众，这意味着该提议不会再更改和变化。

Learner不参与算法的决策过程，英雌它们不是Paxos的重要组成部分，他们可以全部失败或断开连接。之所以说他们可以全部失败，是因为我们随时可以重放已达成共识的提案，从而构建与失败前一摸一样的Learner。

在Paxos中，Learner仅用于实现状态机，执行状态转移操作，这可以理解为所服务的业务实现。例如，在实现一个分布式数据库时，每一条DML语句都是一个提案，每个提案达成共识后，交由Learner执行对应的更新操作，并记录对应的业务数据。

而在工程实现中，Learner承担的更多，它可以实现扩展读性能和同步落后数据。

- 扩展读性能：当Proposer和Acceptor处理客户端的读请求达到瓶颈时，可以扩展Learner。因为他不参与协商过程，增加Learner的数量也不会影响协商效率。另一种情况是，当客户端需要跨地域访问Paxos集群时，可以在客户端所在地域增加Learner，客户端直接访问当前地狱的Learner可以降低读请求的网络延迟。

- 同步落后数据：Paxos允许少数成员数据落后，当集群中的多数派成员的数据处于落后状态时，需要先同步落后数据才能协商新的提案。当新成员上线时，也需要先扮演学习者学习过去已被选择的提案。

### 阶段

#### 1. Prepare阶段

协商过程的开始阶段，当Proposer收到客户端的写请求时，Proposer会为此生成全局唯一的递增的提案编号M，并向所有Acceptor发送包含提案编号的Prepare请求，记作[M, ]。当Acceptor收到提案[M, ]的Prepare请求后，会根据约定的规则决定是否需要响应Prepare的请求。

- 如果M大于Acceptor已经通过的Prepare请求中的最大提案编号，则通过本次Prepare请求，并承诺在当前Prepare请求的响应中，反馈已经批准的Accept请求中最大编号的提案指令；如果没有批准任何Accept请求，则在Prepare请求的响应中反馈Nil。

- 如果M小于等于Acceptor已通过的Prepare请求中最大的提案编号，则拒绝本次Prepare请求，不响应Proposer。

**注意：响应Nil和不响应并非相同的动作。如果不响应，Proposer可以认为该Acceptor拒绝了Prepare请求，或者该Acceptor发生了故障；如果响应Nil，则意味着该Acceptor通过了Prepare请求，并且没有批准任何一个提案**

根据Acceptor处理Prepare请求的规则，如果Acceptor通过了Prepare[M, ]请求。则向Proposer做出以下承诺：

- 不再通过编号小于等于M的提案的Prepare的请求。

- 不再批准编号小于M的提案的Accept请求。

- 如果Acceptor已经批准的提案编号小于等于M的Accept请求，则承诺在提案编号为M的Prepare请求的响应中，反馈已经批准的Accept请求中最大编号的提案指令。如果没有批准任何Accept请求，则在Prepare请求的响应中反馈Nil。

**注意：在Prepare请求中，Proposer只会发送提案编号，也就是[M, ], 提案指令需要根据Acceptor的响应才能确定**

#### 2. Accept阶段

在Proposer收到多数派的Acceptor的响应后，由Proposer向Acceptor发送Accept请求，此时的Accept请求包含提案编号和提案指令，记作提案[M, V]。Acceptor收到提案[M, V]的Accept请求后，会根据以下的约定对Proposer进行反馈。

- 如果Acceptor没有通过编号大于M的Prepare请求, 则批准该Accept请求，即批准提案[M, V]，并返回已通过的最大编号也就是[M, ]

- 如果Acceptor已经通过编号为N的Prepare请求，且N>M, 则拒绝该Accept请求，并返回已通过的最大编号即[M, ]

当前拒绝Accept请求时，Acceptor可以直接忽略Accept请求，不执行响应Proposer的操作，也可以给Proposer反馈自己已通过的最大提案编号，只要让Proposer明确知晓自己的决策，就不会影响Paxos的正确性。

在实践中，无论拒绝或接受Accept请求，Acceptor都会给Proposer反馈自己通过的最大提案编号。因为在下一轮协商中，Proposer可以基于响应中的提案编号进行递增，而不用尝试逐个递增提案编号。而Proposer可以对相应的提案编号和Prepare阶段所使用的提案编号进行比较，如果二者相等，则意味着对应的Acceptor批准了该Accept请求，否则为拒绝。

如果多数派的Acceptor批准了该Accept请求，则记作提案[M, V] 已被选择或者提案已达成共识；如果没有多数派的Acceptor批准该Accept请求，则需要回到Prepare阶段重新进行协商。

**提案中的V值，如果在Prepare请求响应中，部分Acceptor反馈了提案指令，则V为Prepare请求反馈中最大的提案编号对应的提案指令，否则V可以由Proposer任意指定。**

#### 3. Learn阶段

Learn阶段不属于Paxos的协商阶段，它的主要作用时将达成共识的提案交给Learner进行处理，然后执行状态转移操作。如何让Learner知晓已达成共识的提案有以下几种方案：

- 进行Peoposer同步。在协商的过程中，只有提案对应的Proposer才知道提案是否已达成共识和最终达成共识的真正提案。因此在Accept阶段，如果一个提案已达成共识，那么由Proposer立即将该提案发送给Learner是最简单的方案。

- 转发Accept请求给Learner。当Acceptor批准一个Accept请求时，会将其转发给Learner，Learner需要判断是否有多数派的Acceptor给它发送了同样的Accept请求，一决定是否需要执行状态转移，这要求Learner承担一部分属于Paxos的计算能力。

- 在Acceptor之间交换已批准的Accept请求。当Acceptor批准一个Accept请求时，会将其广播给其他Acceptor，那么所有的Acceptor都可以判断提案是否已达成共识，并将达成共识的提案发给Learner。这样做明显又增加了一轮消息交互，但好处是，每个Acceptor都可以为提案记录是否已达成共识的标志，这可以使读请求不必再执行一轮协商。

对于第二种和第三种，当发生提案冲突而导致没有任何提案达成共识时，Learner不会为任何提案执行状态转移操作，本次计算和消息交互就白费了。所以第一种方案仍然是最有效的。但是，通常来说Learner是一个集合，如何高效的让所有Learner都拥有某个已达成共识的提案有三种数据同步的方案：

- 逐一同步
  
  最简单的方式，当触发Learn阶段时，Proposer将逐个向所有的Learner发送需要达成共识的提案。
  
  这种方式虽然简单，但是会增加Proposer的负担，并且同步效率不高，如果Learner数量为N，则需要发送N个消息才能同步。

- 选举主Learner

    将提案发送给其他Learner的工作，由Proposer交给主Learner做。

这种方案解决了Proposer负担过重的问题的同时，引入了新的麻烦：即主Learner的可用性。

为了解决主Learner出现故障的问题，可以选举多个主Learner，同样主Learner集合不能过大，不然会增加Proposer负担。

- 流言传播

    当Learner的集合实在太大的时候，可以考虑留言传播，即Gossip协议。当有数据发生变更时，Gossip通过各个成员之间互相感染来传播数据。Gossip的传播能力是极强的，除非人为阻断传播，否则它会将变更的数据复制到整个集群中，哪怕该集群有成千上万个成员。

## Paxos详解

### Paxos模拟

Paxos的协商过程由4个RPC交互来完成，Prepare、PrepareResp、Accept和AcceptResp。前两者发生在Prepare阶段，后两者发生在Accept阶段。每个RPC消息需要完成的工作如下：

1. 当Proposer收到客户端请求时，首先要为提案生成一个递增的、全局唯一的提案编号N。

2. Proposer向所有Acceptor发送Prepare [N, ]请求。

3. 当Acceptor收到Prepare[N, ]请求后，会和自己所通过的Prepare请求中最大的提案编号MaxNo进行比较。
   
   - 如果N > MaxNo, 则更新MaxNo的值为N，并通过PrepareResp[AcptNo, AcptValue]请求向Proposer反馈自己所批准的最大的提案编号和其对应的提案指令。
   
   - 如果N<= MaxNo， 则忽略本次Prepare请求。

4. 如果Preposer未收到多数派的反馈，则回到Prepare阶段， 递增提案编号，重新协商；如果Proposer收到多数派的反馈，按照以下规则选择提案指令Value，向Acceptor发送Accept[N, Value]请求。
   
   - 如果在反馈中存在一个AcptValue的值不为Nil，则使用所有反馈中提案编号最大的提案指令作为自己的提案指令Value。
   
   - 如果在所有反馈中AcptValue都为Nil，则由Proposer任意指定提案指令为Value。

5. Acceptor收到Accept[N, Value]请求后，回合自己所通过的Prepare请求中最大的提案编号MaxNo进行比较。
   
   - 如果N=MaxNo，则更新自己所批准的提案编号和提案指令，并通过AcceptResp[MaxNo]向Proposer反馈MaxNo。
   
   - 如果N<MaxNo，则忽略本次Accept请求。

6. 如果Proposer未收到多数派的反馈，则回到Prepare阶段，递增提案编号，重新协商；如果Proposer收到多数派的反馈，则说明该提案已被选择，在各个Acceptor之间达成共识。

![](C:\Users\ljc\Documents\GitHub\--\分布式共识算法\图片\paxos模拟.jpg)

### Prepare阶段

在实际情况中存在多个Proposer，这就意味着算法在运行的时候会同时出现多个提案，而每个提案也会影响Prepare和Accept请求。但是只要遵循上述规则，Paxos就一定能保证数据的正确性。

### Accept阶段

如果Proposer没有获得多数派Acceptor的支持，则需要回到Prepare阶段重新协商；如果获得了多数派Acceptor的支持，就可以开启Accept阶段，使提案指令在各个成员之间达成共识。

在发送Accept请求之前，Proposer还需要先确定提案指令。如果在Prepare请求响应中提案指令不是Nil，则选择所有响应中，提案编号最大的那个提案指令作为自己的提案指令，如果在所有的响应中提案指令都为Nil，则可以由Proposer自己指定提案指令。

在实际项目中，为了保证已达到共识的提案，不再改变，约定Proposer阶段需要返回上一轮Accept阶段可能达到共识的提案，具体如下：

- 如果Acceptor已经批准了任意的Accept请求，则承诺在PrepareResp请求中反馈已批准的提案编号和已批准的提案指令。

- Proposer需要从PreposerResp请求中找出最大的提案编号作为自己的提案指令。

我们想象这样一个场景，Proposer B发出的Prepare_B[3, ]请求获得了多数派Acceptor的支持，随后发起Accept_B[3, Mod]请求，在此过程中Proposer A发起Prepare_A[4, ]请求。各个Acceptor收到请求的顺序及处理情况如下：

- Acceptor A 先收到Accept_B[3, Mod]请求，再收到Prepare_A[4, ]请求，按照约定会批准Accept_B[3, Mod]请求，也会通过Prepare_A[4, ]请求，并向Prepare A反馈PrepareResp_A[3, Mod]。

- Acceptor B 和Acceptor C先收到Prepare_A[4, ]请求，再收到Accept_B[3, Mod]请求，按照约定会拒绝Accept_B[3, Mod]请求。

此时Accept_B[3, Mod]请求未获得多数派支持。Prepare_A[4, ]请求获得了多数派的支持，但是在Prepare_A[4, ]请求的反馈中包含非Nil的提案指令，即[3, Mod]。因此Proposer A会选择Mod作为自己的提案指令，并发起Accept_A[4, Mod]请求给各个Acceptor。

### 活锁

活锁是指多个Proposer同时发起提案时，每个提案的Prepare请求和Accept请求交叉运行，相互干扰，导致最终选不了任何一个提案。

Proposer A和Proposer B同时发起提案Proposer A发起[1, ], B发起[2, ], Prepare_A[1, ]获得多数派支持后，在发起Accept[1, ]之前，B发起了Prepare_B[2, ], 之后Acceptor根据约定会拒绝Accept_A[1, ],在Proposer B 发起Accept_B[2, ]之前， Proposer A 发起Prepare_A[3， ]，Acceptor们又会拒绝Accept_B[2, ]，导致循环往复下去。

为了缓解这个问题，在生产实践中，可以设定最小发起协商的超时，也就是说，在这个时间内，擢内阁给其他Proposer一个机会，避免争夺。约定Proposer的Accept请求遭到拒绝后，需要等待最小发起协商的超时后，才允许发起下一轮的协商。而这个超时需要远大于正常协商所需要的时间，这样才能保证不干扰其他Proposer的协商进程。

另外，Lamport在论文中也提到了Multi Paxos的解决方案，可以有效解决提案冲突。即通过减少发起协商的成员数量来降低提案发生冲突的 概率。另外，在Multi Paxos的基础上还可以进一步降低活锁带来的影响，这一点在PhxPaxos中已经进行了深入实践。

### 提案编号选定

生成提案编号，要保证任意两个提案编号都不相同，且自增，最简单的方式是有一个提案编号服务器，但问题也很明显，就是无法保证这个额外服务的可靠性。

也可以使用Timestamp作为提案编号的高位，成员的唯一ID作为低位，只要时间误差不过大，就能保证提案编号的唯一递增。

## Paxos的推导过程

首先，分布式环境棉铃的问题：在由多个成员组成的集群中，如果某一个值或指令被选择了，那么客户端无论访问哪个成员都会返回相同的值或指令。仔细分析，它包含多个含义：

1. 客户端会发出多个指令，每个成员所认可的值或指令都应该一样。

2. 只有一个值或指令被集群选中，它才能被客户端所获取。

3. 传送的通道不可靠，可能存在消息丢失、消息延迟等情况，但不考虑拜占庭故障故障模型。

4. 服务器不可靠，应该允许少部分成员出现故障的情况。

由于单个Acceptor总有一天会停机，到时候整个系统不可用。因此多个Acceptor共同选择提案才是可靠的。如果Proposer向一组Acceptor发起提案指令，那么怎样才算该提案指令被选中呢？是否有必要约定所有的Acceptor都批准某一天指令才算该提案指令被选中？当然不是，因为Acceptor会出现故障，要求全部批准是苛刻的，也是没有必要的。只需要多数派的Acceptor批准同一个提案指令即可。

需要多数Acceptor批准的原因是两个多数派提案指令之间至少会存在一个共同的Acceptor，为了保证达成共识的提案指令的唯一性，即不存在两个提案指令被同时选择的情况，我们要求这个共同的Acceptor只能批准一个提案指令，这样就能保证共识算法的正确性。因此，我们要求所有的Acceptor只能批准它收到的第一个提案指令即可满足这一要求，即得到P1。

    P1. Acceptor必须批准他接受的第一个提案指令。

    按照P1执行算法，存在投票被瓜分的情况。如果每个Acceptor都批准它接受的第一个提案指令，那么可能导致每个提案指令只获得一个Acceptor的支持，最终所有的提案指令都没有获得多数派的支持，即没有一个提案指令被选择。这意味着Acceptor不能只批准第一个提案指令，应该允许它批准多个提案指令；同时为了保证算法的安全性，在Acceptor批准的所有提案指令中，同一时间只能有一个有效的提案指令，这个有效的提案指令就是在当前时刻Acceptor所认可的提案指令。如何确定哪个提案指令有效：

    需要给提案指令增加一个提案编号，即[提案编号， 提案指令]表示一个提案，用最大的提案编号表示最新的有效提案。由于Acceptor允许批准多个提案，因此就不能用任意值作为提案指令了。原因是，当一个提案[M, V]获得多数派支持时，V就已经被选择了，如果Acceptor还能批准后续的提案，那么就必须要求后续Acceptor批准的提案指令也为V。

    P2. 如果一个提案[M, V]被选择了，那么后续被批准的标号更高的提案所包含的提案指令也都是V。

    如果一个提案被选择了，那么一定存在一个及以上的Acceptor批准了该提案，继续完善P2会得到P2A。只要能保证P2A，就能满足P2。

    P2A. 如果一个提案[M, V]被选择了，从那么任何Acceptor批准的编号更高的提案所包含的提案指令也都是V。

    只要求Acceptor是不足以保证安全性的。试想一下，如果存在两个Proposer，第一个[M1, V1]已经获得了多数派集合Q1的支持，即被选择了。此时第二个Proposer提出了提案[M2, V2]，且M2 > M1, V2 != V1,并将提案发送给了Acceptor C ，且C 不属于Q1。按照P1约定，C应该批准[M2, V2]，但是却违背了P2A。

    因此，需要继续增强P2A，从天提出的时候开始约定提案指令，进而得出P2B。

    P2B. 如果一个提案[M,V]被选择了，那么此后没任何Proposer提出的编号更高的提案包含的提案指令都是V。

    因为如果一个提案被选择了，那么一定是被Proposer提出过的，也就是说P2B包含P2A，只要满足P2B就能满足P2A。

接下来考虑如何满足P2B，只需要在[M1, V1]被选择时，保证任意编号为Mn的提案指令为V1即可。一个提案[M1, V1]被选中，一定是获得了多数派Q1的支持，同时两个多数派集合中一定存在一个共同的Acceptor，所以约定，在提案[Mn, Vn]提出之前，一定存在一个由Acceptor组成的多数派Qn满足以下任意一个条件，就能满足Vn=V1.

- 条件一：在Qn中没有Acceptor批准编号小于Mn的提案。

- 条件二：在Qn的任意一个Acceptor批准的所有提案（编号小于Mn）中，Vn时编号最大对应的提案指令。

满足条件一就能满足P2B，这个容易理解。

对于条件二，需要用归纳法理解。在Proposer提出提案[M2, V2]时，多数派Q2需要满足条件二，即V2是Q2中任意一个Acceptor批准的最大编号的提案指令。而Q2与提案[M1, V1]的多数派集合Q1的交集一定不为空，同时在Q1中任意一个Acceptor批准的提案指令都为V1，这意味着V2=V1。以此类推Vn-1 = V1，因此满足条件二Vn一定等于V1。

    通过上述总结得出P2C，只需满足P2C的要求就满足P2B，进而满足P2A，从而满足P2.

    P2C. 对于任意的M和V，如果[M, V]被提出，那么一个由Acceptor的多数派组成的集合满足以下任意一个条件：

- 条件一：在Q中没有Acceptor批准编号小于M的提案；

- 条件二：在Q的任意一个Acceptor批准的所有提案（编号小于M）中，V是编号最大的提案指令。

从P2C来看，一个提案的提出，需要先由Proposer确定提案指令，这自然不是在一阶段就能完成的。Proposer在正式发起提案之前，需要先和多数派的Acceptor取得联系，并询问编号为M的提案指令。Acceptor可以给Proposer返回没有批准过的提案指令(P2C条件一)；也可以给Proposer返回已批准的最大编号的提案指令，因此Proposer需要从所有的响应中选择最大编号的提案指令作为V，进而满足P2C条件二。

同时，Acceptor不能在反馈Proposer上述两种响应之后，立刻批准一个编号比M小的提案指令。因为这有可能在提案[M, V]提出的那一刻违背了P2C的条件。

因此，Proposer在询问提案指令的同时也要求Acceptor不能批准提案编号小于自己询问的提案编号，并且Proposer发起的提案指令需要根据询问结果来指定，这样就推导出了Proposer整个的实现过程。

1. Proposer生成提案编号M并将提案编号发送给Acceptor（即Prepare请求），然后询问所批准的提案指令并要求Acceptor回应。
   
   - 一个不再批准编号小于等于M提案指令的承诺。
   
   - 如果已批准编号小于M的提案，则反馈最大编号对应的提案指令。

2. 如果Proposer收到多数派的反馈，那么就可以提出提案[M, V]并发送给Acceptor（Accept请求），其中，V是反馈中编号最大的提案指令，或者是Proposer指定的任意指令。

以上是Proposer的工作过程，下面推导Acceptor工作过程。

Acceptor会受到两种来自Proposer的请求：Prepare请求和Accept请求。Prepare请求可以理解为Acceptor向Proposer按照约定许下承诺；Accept请求则是履行承诺。只有当Acceptor没有通过编号大于M的Prepare请求时，才能批准编号为M的Accept请求。由于该承诺，Acceptor也可以放弃那些编号较小的Prepare请求。

因此，Acceptor的算法内容很简单，只需要履行对Proposer的承诺即可，即P1A.

    P1A. 当且仅当Acceptor没有通过一个编号大于M的Prepare请求时，它才可以批准一个编号为M的提案指令。

整理Proposer和Acceptor的工作内容，可以得到Paxos在两个阶段的协商过程。

Prepare阶段：

- Proposer生成唯一的提案编号M， 通过Prepare请求给Acceptor发送编号。

- Acceptor收到Prepare请求，如果M小于等于自己之前批通过的Prepare请求的最大编号，则拒绝该Prepare请求；否则，Acceptor通过该Prepare请求，并向Proposer反馈约定的内容。反馈内容为已批准的Accept请求最大编号对应的提案指令（如果存在的话）。

Accept阶段：

- Propsoer在收到多数派Acceptor的反馈后，可以发起提案[M, V]，其中V为反馈的最大编号对应的提案指令，或者自由指定。通过Accept请求给Acceptor发送提案。

- Acceptor收到Accept请求后，如果M小于自己之前通过的Prepare请求的最大编号N，则Acceptor拒绝该Accept请求；否则批准，向Proposer反馈通过的Prepare请求的最大编号M。

- Proposer在收到多数派Acceptor的反馈后，意味着该提案已被选择，即达成共识；否则，需要回到Prepare阶段，重新协商。

### 多数派的本质

多数派的思想贯穿整个Paxos，而多数派只是一种实现方式。了解多数派的本质，需要重新审视Prepare和Accept两阶段的含义。

## Multi Paxos详解

解决Basix Paxos痛点

### Multi Paxos简介

Basic Paxos需要多轮的Prepare和Accept才能对一个值达成共识，RPC交互次数多，则网络延迟也会相应增大，加上活锁的存在概率。实际上Basix Paxos的协商效率是很低的。因此，可以考虑省略一些非关键性的交互，以找到一个优化的方案。

根据经验，较低的消息复杂度可以提高吞吐量，在同等的带宽中，传输通道的大小是不变的，消息交互的次数变少了，自然有更多的带宽可以用于发送实际的提案命令。

之所以叫做Multi Paxos是因为一开始他想解决的问题就是运行一轮Paxos，使多个值或指令达成共识。为了实现这个目标，相比于Basic Paxos，Multi Paxos有以下几点改进：

- 引入Leader角色，只能由Leader发起提案，优化第一阶段。

- 在没有提案冲突的情况下，省略Prepare阶段，优化成一阶段。

Multi Paxos允许同时存在多个自认为是Leader的成员，并允许它们同时发起提案。当多个Leader同时发起提案，不会影响正确性，但是Leader成员的个数并不会与写性能成正比。相反，大批量的Leader存在，将会导致写性能效率退化到Basic Paxos。在实际情况中，希望大部分时间只有一个Leader。

### Leader选举

引入Leader使Multi Paxos的关键，可以认为Leader是特殊的Proposer。

一种实现方式是，在集群没有Leader的时候，运行一轮Basic Paxos，选举出新的Leader并让其他成员认可。然后由该Leader发起提案。这种方式是没有必要的，Leader本身并不需要可以选举，因为它本身就是特殊的Proposer，只是在优化Prepare阶段的过程中给Proposer区的一个新名字。

引入Leader的原因：运行一轮Paxos，使多个提案达成共识。要使一轮Paxos的多个提案达成共识，就需要找到多个提案指令之间的联系。

Prepare阶段就是为了之后的Accept阶段而让Acceptor做出承诺，保证后续的Accept阶段可以执行，并且不会被打扰，因此假设现在，集群收到了多个请求，正常会有多个Prepare请求，从1至N。而如果某个Proposer的编号N获得多数派支持，那么该Proposer将不再更新N的值，且不存在当其他Proposer尝试获得Acceptor的承诺时，Promise的编号一直为N的情况。也就是说多数派Acceptor对该Proposer做出的承诺一直有效。因此，该Proposer可以使用编号N发起多个Accept请求，从而使多个提案指令达成共识。

但是这个优化只是基于一个Proposer的，于是引入了Leader的角色，只能由Leader发起提案，并允许多个Leader同时发起提案。但是要求在Leader发起提案之前先执行一次Prepare阶段的任务，以获得多数派Acceptor的承诺；如果Acceptor承诺了一个新的更大的编号，那么其之前对Leader的承诺将失效。

这时的提案编号更像是Leader的任期编号。

虽然允许多个Leader的存在，但是由于Leader之间会相互干扰，一个Leader的Prepare阶段会打断另一个Leader的Accept阶段。因此，选择单一额度Leader只是为了保证算法的活跃程度u，避免出现活锁。

为了保证Leader的身份，确保连续的Accept阶段，引入**租赁机制**

只需要要求Acceptor收到一个心跳消息或者Accept请求后，在一个租期内拒绝发起Prepare请求即可。这就意味着不会有新的Leader诞生。

因此推荐的Leader选举方式是：不需要可以选举，只需要Acceptor按照约定进行运算，Leader就会被选举出来。在其他资料中，也把Prepare阶段称为Leader选举。

## 工程实现

### 一些优化

1. NACK消息：
   
       可以观察到，Proposer在处理PrepareResp和AcceptResp时，至少需要等待多数派的反馈才能做出判断。当Proposer提案编号落后于集群时，它一定获取不到多数派的反馈，只能等待出发超时策略。
   
       NACK消息是指Acceptor在处理Prepare和Accept请求的时候，当提案编号N<MaxNo的时候，Acceptor不忽略，而是返回NACK消息，加快Preopare的收敛。另外，可以在NACK中携带MaxNo。避免一个个尝试。

2. 跳过Accept阶段：
   
   如果在Prepare阶段收到多数派的Acceptor都批准了某一个提案指令，则可以直接结束协商。因为在过去的某个时刻，这个提案已经达成共识了，只是未被集群知晓。

3. Confirm请求
   
   Proposer在Accept阶段得到多数派的支持后，发送一轮Confirm请求给所有的Acceptor，通知Acceptor为该提案记录已达成共识的标胶。
   
   后续如果Acceptor收到其他Proposer发出的Prepare和Accept请求，则可以直接告诉Proposer，这个提案已经达成共识，不用再执行Accept阶段工作。
   
   同时Confirm请求是不用携带提案指令的，只需要携带提案指令的摘要即可。因为当发起Confirm请求的条件一定时，Proposer已经明确知道该提案复制了多数派的Acceptor，所以只需要告诉Acceptor某个提案已达成共识即可，摘要用于Acceptor哦按段自己批准的提案指令和达成共识的是不是一个。
   
   对于那些没有拥有该提案的Acceptor，或者不相等的，需要执行一轮Prepare来获取该提案。

4. 选举Proposer
   
   多个Proposer的协商进程会互相影响产生活锁，因此可以选举一个特殊意义的Proposer，在算法运行的过程中，其他成员把收到的写请求都转发给该Proposer，让他单独发起协商，这样可以极大减少产生活所的概率。

5. 准备资源
   
   在主被截断是不会发出提案指令的，而会争取发起提案指令的所有权。因此，Prepare可以在收到客户端请求之前执行任务，收到客户端请求后可以直接执行Accept阶段的任务。
   
   如果有一些成员已经批准了某个提案指令，则可以提前执行Prepare阶段的任务，这样能尽早发现情况，从而进行进行下一轮协商。

6. 多角色部署
   
   在实际场景中，一个成员同时扮演Proposer、Acceptor、Learner。好处是：同一个物理成员中的三个角色可以共享数据，节省了至少一轮Proposer->Acceptor、Proposer->Learner。

7. Quorum的动态调整
   
   为了最大化提升读请求，可以控制QuorumR（处理Prepare阶段的成员集合）成员数量为1，QuorumW（处理Accept阶段的成员集合）成员数量为N。 这样任意一个Acceptor都可以根据自己的本地数据来处理读请求。在处理写请求的时候，需要搜有的Acceptor的支持才算达成共识。这么做的话，明显是写请求不能再容忍故障了。不过没关系，在写请求持续出错时，可以继续调整Quorum，使其能够继续满足容错。$R = W = \lfloor N / 2 \rfloor + 1$
   
   接下来的协商重新以多数派进行抉择，自然也能容忍少数派发生故障。
   
   动态调整Quorum设定，最重要的是需要权衡写请求出错的次数，在达到约定的出错次数后，才需要动态调整Quorum。

### 对读请求进行优化

正常来说，Paxos负责提案的协商，最终的提案指令会输入状态机，而状态机通常会提供与业务相关的读服务。读请求的应用场景相对较少，但还是要了解一下。例如，日志重放和新成员上线，都需要获取过去已被选择的提案，本小节中的客户端是指需要获取提案的成员，如刚上线的成员。

由于Paxos的写请求只需要多数派正常响应即可，所以会造成任意两个Acceptor之间对提案批准的情况不一致，因此处理读请求不能由Acceptor承担，而是由Leader、Proposer或Learner来处理。

由于Leader和Proposer不参与提案的选择，所以它们不知道在某个Instance上选择了哪个提案，最终导致读请求也需要执行一轮Paxos，在Prepare阶段收到多数派相同的响应后，才能明确回应客户端。这里，在Prepare阶段，会出现以下三种情况：

- 情况一：在多数派的响应中，AcptValue都为Nil，意味着该Instance项没有任何提案被选择，直接给客户端返回没有提案被选择指令即可。

- 情况二：在多数派的响应中，AcptValue相同，意味着该AcptValue已被选择，在这种情况下也可以明确地向客户端返回AcptValue就是已被选择的指令即可。

- 情况三：在不满足情况一和情况二的条件下，当出现任意个AcptValue不为Nil时，需要选取AcptNo最大的AcptValue作为Accept请求的提案指令，使得多数派批准该AcptValue之后，才能给客户端返回AcptValue已被选择的命令。

在工程实践中，为了让更多的成员处理读请求，而不是都给Leader处理，解决这一问题的根本方案是，让Acceptor成员明确知道那些提案被多数派批准了，这样Acceptor就可以根据自己的数据响应客户端了，而不用再麻烦Leader执行一轮Leader。为了让所有处理读请求的Acceptor都能知道哪些提案被多数派批准，有以下三种方案：

1. Acceptor之间相互广播所批准的Accept请求，这样Acceptor就可以通过计算多数派来判断提案是否已经达到共识，并为该提案记录已达成共识的标记。对于未记录达成共识的Paxos，仍需一轮Paxos。

2. 引入Confirm请求，这是在实际工程中深入实践过的方案。即在Accept阶段的提案达成共识后，Leader向Acceptor发送一轮Confirm请求，通知该提案已经达成共识，这些Acceptor则为其记录已达成共识的标记。处理Confirm请求相对简单，只需要插入一条对应Instance项的Confirm日志，如果存在Confirm日志，则直接返回给客户端对应的内容即可，若不存在就通知Leader进行一轮Paxos协商，并记录Confirm日志。

3. Learner也是处理读请求的好手，由于Learner只会接受已达成共识的提案，所以让Learner在执行状态转移之前顺便记录提案数据即可。

读取提案是为了构建新的状态机，而Learner本身就包含状态机的数据。可以让Learner为状态机生成快照文件，当需要构建新的状态机时，同步快照文件即可，无需将国王的提案逐一同步给新成员，然后一条一条输入状态机。

采用Learner处理读请求需要注意，Learner的提案数据会有延迟，处理读请求的Learner本身就是有提案数据缺失的。在实际场景中，可以结合其他方案开发出更高效的系统。例如，新成员上线时，可以先向Learner索取快照文件，然后通过执行Prepare阶段的任务获取在快照中不存在的提案数据。具体的快照实现还包含CheckPoint的设定。

### 并行协商

串行协商效率低。

由于每个Instance都是独立的，所以可以并发协商，在Instance51未被选择之前，在Instance52上提出下一个提案。

并行协商可能出现以下几个问题：

- 在Instance52已选择出提案之后Instance51可能会协商失败，这时会出现中断的Instance项。极端情况下，假设允许N个Instance并发协商，会出现最多N个空洞的Instance项。

- 当成员变更时，需要考虑给正在协商中的Instance项一个比较大的缓冲时间。

- 对于已达成共识的Instance，需要等它之前的Instance达成共识之后才能输入状态机，

为了支持并发协商mLearner需要严格按照Instance顺序执行状态转移操作而并发协商存在空洞Instance时，需要使用默认提案（NOOP）进行协商，使其达到共识后才能继续将后续Instance的提案输入状态机。

### Instance的重确认

虽然Multi Paxos引入了Leader角色，但本质上还是属于去中心化算法或弱中心化算法。当新的Leader晋升时，他并不知道上一任Leader有哪些提案已经达成共识了，因此Leader需要对一些不确定的Instance进行重确认，即再执行一轮Paxos。

虽然可以通过Confirm请求记录达成公示的标记，但是上一任Leader有可能未完成提案协商。不确定的Instance分为两类：

- 新Leader已批准，但不知道是不是多数派批准的Instance。

- 新Leader未批准的Instance。

#### 1. 新Leader已批准的Instance

在执行一轮Paxos进行重确认。

在实践中，对每一个Instance进行重确认代价太大，因此只需要对没有Confirm日志的Instance项进行重确认即可。同时，在正常协商的时候，允许丢失任意数量的Confirm，因为，新的Leader会推进没有Confirm的Instance项的Confirm请求。

#### 2. 新Leader未批准的提案

由于Paxos允许少数成员数据落后，而如果这些成员成为了新的Leader后，需要不全这些”空洞“。

新Leader询问所有成员InstanceId最大的Instance项，然后以这个为结束Instance项，不全这些空的Instance项，并且记录Confirm日志。

### 幽灵日志

幽灵日志是由于冲确认设计不当而引发的错误，他可能会使多次读请求之间返回给客户端的结果不一样。

幽灵日志出现的根本原因是Paxos将一个不确定的Instance响应发给了客户端，而一个确定的Instance只有一种状态，即共识状态。

解决幽灵日志的方案是结合Confirm请求，在处理读请求的时候，一定要明确Instance已记录Confirm日志才能返回结果。

![](C:\Users\ljc\Documents\GitHub\--\分布式共识算法\图片\幽灵日志.jpg)

## Paxos在PhxPaxos中的应用

Phx实现了以下功能：

- 在无冲突的情况下，优化Prepare阶段，节省了RPC交互和写盘次数

- 引入Paxos-Group，多个分组之间可以并行协商多个值

- 批量协商，将多个请求合并，提高吞吐量。

- 可以后接任意实现的状态机，适应多种应用场景。

- 数据落后成员可向集群内的任意成员学习同步数据。

### PhxPaxos分析

#### 1. PhxPaxos应用场景

暂省略

## 练习题

1. 为什么需要有多个Acceptor？单个Acceptor有什么问题？
   
   多个Acceptor，一是为了保证以达成的提案不会丢失，二是提供能容忍发生故障的能力。
   
   单个Acceptor就是单点故障，无法保证可用性和安全性？

2. 提案编号解决了什么问题？
   
   一是判断消息的有效性，选择忽略那些小于自己的提案编号的消息。
   
   二是为了标识当前所批准的提案。

3. 有三个成员的集群A、B、C，其中，A和B批准提案[4,6]，C没有通过任何提案。此时C收到客户端请求，提案指令为5且C的提案编号为4.通过Basic Paxos后，最后集群的每个成员批准的提案应该是什么？
   
   [5, 6]

4. 有五个成员的集群A、B、C、D、E，其中，A、B批准提案[1,X], D、E批准提案[2, Y]。这是另一个提案的Prepare请求发起提案Prepare[3, ]，按照P2C约定，A、B返回[1, X]作为响应，D、E返回[2, Y]作为响应，那么这时编号为3的提案值使用X还是Y？
   
   Y

5. Multi Paxos在没有提案冲突的情况下，在Prepare阶段最少执行多少次，最多执行多少次？
   
   一次，无数次

6. 有三个成员的集群A、B、C，其中A发起PrepareA[1, ]请求获取A、B、C的支持 ，B发起PrepareB[2, ]请求获取B、C的支持， 二者都获得了多数派支持，并且提案指令都由自己指定。Proposer A发送AcceptA[1,X]， Proposer B发送AcceptB[2, Y]。最终A批准提案[1, X]，B、C批准提案[2, Y]，这样就形成一致性了么？
   
   Paxos允许这种情况存在。多数派保持一致就可以。最终AcceptB[2, Y]也会到达A。那时再批准就可以。


